{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "LOGS_PATH = \"../../image2sdf/logs/decoder/log.pkl\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logs = pickle.load(open(LOGS_PATH, 'rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logs.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(logs[\"sdf\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "avrg_sdf = []\n",
    "for i in range(len(logs[\"sdf\"]) - 246):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    avrg_sdf.append(np.mean(logs[\"sdf\"][i : i + 246]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(np.mean(logs[\"sdf\"][-246:]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.00021642382\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "\n",
    "from networks import Decoder\n",
    "from dataLoader import DatasetDecoder\n",
    "from marching_cubes_rgb import *\n",
    "\n",
    "import IPython\n",
    "\n",
    "# directory which contain the SDF input and where all the output will be generated\n",
    "MAIN_DIR = \"../../image2sdf/\"\n",
    "# MAIN_DIR = \"/home/loic/MasterPDM/image2sdf/\"\n",
    "\n",
    "DECODER_PATH = \"models_and_codes/decoderSDF.pth\"\n",
    "LATENT_CODE_PATH = \"models_and_codes/latent_code.pkl\"\n",
    "LOGS_PATH = \"../../image2sdf/logs/log.pkl\"\n",
    "PARAM_FILE = \"config/param.json\"\n",
    "\n",
    "SDF_DIR = MAIN_DIR + \"sdf/\"\n",
    "RESOLUTION = 64\n",
    "\n",
    "\n",
    "\n",
    "def init_xyz(resolution):\n",
    "    \"\"\" fill 3d grid representing 3d location to give as input to the decoder \"\"\"\n",
    "    xyz = torch.empty(resolution * resolution * resolution, 3).cuda()\n",
    "\n",
    "    for x in range(resolution):\n",
    "        for y in range(resolution):\n",
    "            for z in range(resolution):\n",
    "                xyz[x * resolution * resolution + y * resolution + z, :] = torch.Tensor([x/(resolution-1)-0.5,y/(resolution-1)-0.5,z/(resolution-1)-0.5])\n",
    "\n",
    "    return xyz\n",
    "\n",
    "def init_lat_vecs(num_scenes, latent_size):\n",
    "    \"\"\"initialize random latent code for every model\"\"\"\n",
    "\n",
    "    lat_code_mu = torch.nn.Embedding(num_scenes, latent_size).cuda()\n",
    "    torch.nn.init.normal_(\n",
    "        lat_code_mu.weight.data,\n",
    "        0.0,\n",
    "        1.0,\n",
    "    )\n",
    "    lat_code_log_std = torch.nn.Embedding(num_scenes, latent_size).cuda()\n",
    "    torch.nn.init.normal_(\n",
    "        lat_code_log_std.weight.data,\n",
    "        0.0,\n",
    "        0.0,\n",
    "    )\n",
    "\n",
    "    return lat_code_mu, lat_code_log_std\n",
    "\n",
    "def init_opt_sched(decoder, lat_vecs_mu, lat_vecs_log_std, param):\n",
    "    \"\"\" initialize optimizer and scheduler\"\"\"\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {\n",
    "                \"params\": decoder.parameters(),\n",
    "                \"lr\": param[\"eta_decoder\"],\n",
    "            },\n",
    "            {\n",
    "                \"params\": lat_vecs_mu.parameters(),\n",
    "                \"lr\": param[\"eta_latent_space_mu\"],\n",
    "            },\n",
    "            {\n",
    "                \"params\": lat_vecs_log_std.parameters(),\n",
    "                \"lr\": param[\"eta_latent_space_std\"],\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=param[\"gammaLR\"])\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def compute_time_left(time_start, model_count, num_model, epoch, num_epoch):\n",
    "    \"\"\" Compute time left until the end of training \"\"\"\n",
    "    time_passed = time.time() - time_start\n",
    "    num_model_seen = epoch * num_model + model_count\n",
    "    time_per_model = time_passed/num_model_seen\n",
    "    estimate_total_time = time_per_model * num_epoch * num_model\n",
    "    estimate_time_left = estimate_total_time - time_passed\n",
    "\n",
    "    return estimate_time_left\n",
    "\n",
    "def compute_loss(pred_sdf, pred_rgb, sdf_gt, rgb_gt, threshold_precision, param):\n",
    "    \"\"\" compute sdf, rgb and regression loss \"\"\"\n",
    "\n",
    "    loss = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "    # assign weight of 0 for easy samples that are well trained\n",
    "    weight_sdf = ~((pred_sdf > threshold_precision).squeeze() * (sdf_gt > threshold_precision).squeeze()) \\\n",
    "        * ~((pred_sdf < -threshold_precision).squeeze() * (sdf_gt < -threshold_precision).squeeze())\n",
    "\n",
    "    #L2 loss, only for hard samples\n",
    "    loss_sdf = loss(pred_sdf.squeeze(), sdf_gt)\n",
    "    loss_sdf = (loss_sdf * weight_sdf).sum()/weight_sdf.count_nonzero()\n",
    "    loss_sdf *= param[\"lambda_sdf\"]\n",
    "\n",
    "    # loss rgb\n",
    "    loss_rgb = loss(pred_rgb, rgb_gt)\n",
    "    loss_rgb = ((loss_rgb[:,0] * weight_sdf) + (loss_rgb[:,1] * weight_sdf) + (loss_rgb[:,2] * weight_sdf)).sum()/weight_sdf.count_nonzero()\n",
    "    loss_rgb *= param[\"lambda_rgb\"]\n",
    "    \n",
    "    # regularization loss\n",
    "    loss_kl = (-0.5 * (1 + lat_code_log_std.weight - lat_code_mu.weight.pow(2) - lat_code_log_std.weight.exp())).mean()\n",
    "    loss_kl *= param[\"lambda_kl\"]\n",
    "\n",
    "    return loss_sdf, loss_rgb, loss_kl\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "print(\"Loading parameters...\")\n",
    "\n",
    "# load parameters\n",
    "param_all = json.load(open(PARAM_FILE))\n",
    "param = param_all[\"decoder\"]\n",
    "\n",
    "resolution = RESOLUTION\n",
    "num_samples_per_model = resolution * resolution * resolution\n",
    "threshold_precision = 1.0/resolution\n",
    "\n",
    "# get models' hashs\n",
    "list_model_hash = []\n",
    "for val in glob.glob(SDF_DIR + \"*.h5\"):\n",
    "    list_model_hash.append(os.path.basename(val).split('.')[0])\n",
    "num_model = len(list_model_hash)\n",
    "\n",
    "# fill a xyz grid to give as input to the decoder \n",
    "xyz = init_xyz(resolution)\n",
    "\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading parameters...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "\n",
    "from networks import Decoder\n",
    "from dataLoader import DatasetDecoder\n",
    "from marching_cubes_rgb import *\n",
    "\n",
    "import IPython\n",
    "\n",
    "# directory which contain the SDF input and where all the output will be generated\n",
    "MAIN_DIR = \"../../image2sdf/\"\n",
    "# MAIN_DIR = \"/home/loic/MasterPDM/image2sdf/\"\n",
    "\n",
    "DECODER_PATH = \"models_and_codes/decoderSDF.pth\"\n",
    "LATENT_CODE_PATH = \"models_and_codes/latent_code.pkl\"\n",
    "LOGS_PATH = \"../../image2sdf/logs/log.pkl\"\n",
    "PARAM_FILE = \"config/param.json\"\n",
    "\n",
    "SDF_DIR = MAIN_DIR + \"sdf/\"\n",
    "RESOLUTION = 64\n",
    "\n",
    "\n",
    "\n",
    "def init_xyz(resolution):\n",
    "    \"\"\" fill 3d grid representing 3d location to give as input to the decoder \"\"\"\n",
    "    xyz = torch.empty(resolution * resolution * resolution, 3).cuda()\n",
    "\n",
    "    for x in range(resolution):\n",
    "        for y in range(resolution):\n",
    "            for z in range(resolution):\n",
    "                xyz[x * resolution * resolution + y * resolution + z, :] = torch.Tensor([x/(resolution-1)-0.5,y/(resolution-1)-0.5,z/(resolution-1)-0.5])\n",
    "\n",
    "    return xyz\n",
    "\n",
    "def init_lat_vecs(num_scenes, latent_size):\n",
    "    \"\"\"initialize random latent code for every model\"\"\"\n",
    "\n",
    "    lat_code_mu = torch.nn.Embedding(num_scenes, latent_size).cuda()\n",
    "    torch.nn.init.normal_(\n",
    "        lat_code_mu.weight.data,\n",
    "        0.0,\n",
    "        1.0,\n",
    "    )\n",
    "    lat_code_log_std = torch.nn.Embedding(num_scenes, latent_size).cuda()\n",
    "    torch.nn.init.normal_(\n",
    "        lat_code_log_std.weight.data,\n",
    "        0.0,\n",
    "        0.0,\n",
    "    )\n",
    "\n",
    "    return lat_code_mu, lat_code_log_std\n",
    "\n",
    "def init_opt_sched(decoder, lat_vecs_mu, lat_vecs_log_std, param):\n",
    "    \"\"\" initialize optimizer and scheduler\"\"\"\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {\n",
    "                \"params\": decoder.parameters(),\n",
    "                \"lr\": param[\"eta_decoder\"],\n",
    "            },\n",
    "            {\n",
    "                \"params\": lat_vecs_mu.parameters(),\n",
    "                \"lr\": param[\"eta_latent_space_mu\"],\n",
    "            },\n",
    "            {\n",
    "                \"params\": lat_vecs_log_std.parameters(),\n",
    "                \"lr\": param[\"eta_latent_space_std\"],\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=param[\"gammaLR\"])\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def compute_time_left(time_start, model_count, num_model, epoch, num_epoch):\n",
    "    \"\"\" Compute time left until the end of training \"\"\"\n",
    "    time_passed = time.time() - time_start\n",
    "    num_model_seen = epoch * num_model + model_count\n",
    "    time_per_model = time_passed/num_model_seen\n",
    "    estimate_total_time = time_per_model * num_epoch * num_model\n",
    "    estimate_time_left = estimate_total_time - time_passed\n",
    "\n",
    "    return estimate_time_left\n",
    "\n",
    "def compute_loss(pred_sdf, pred_rgb, sdf_gt, rgb_gt, threshold_precision, param):\n",
    "    \"\"\" compute sdf, rgb and regression loss \"\"\"\n",
    "\n",
    "    loss = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "    # assign weight of 0 for easy samples that are well trained\n",
    "    weight_sdf = ~((pred_sdf > threshold_precision).squeeze() * (sdf_gt > threshold_precision).squeeze()) \\\n",
    "        * ~((pred_sdf < -threshold_precision).squeeze() * (sdf_gt < -threshold_precision).squeeze())\n",
    "\n",
    "    #L2 loss, only for hard samples\n",
    "    loss_sdf = loss(pred_sdf.squeeze(), sdf_gt)\n",
    "    loss_sdf = (loss_sdf * weight_sdf).sum()/weight_sdf.count_nonzero()\n",
    "    loss_sdf *= param[\"lambda_sdf\"]\n",
    "\n",
    "    # loss rgb\n",
    "    loss_rgb = loss(pred_rgb, rgb_gt)\n",
    "    loss_rgb = ((loss_rgb[:,0] * weight_sdf) + (loss_rgb[:,1] * weight_sdf) + (loss_rgb[:,2] * weight_sdf)).sum()/weight_sdf.count_nonzero()\n",
    "    loss_rgb *= param[\"lambda_rgb\"]\n",
    "    \n",
    "    # regularization loss\n",
    "    loss_kl = (-0.5 * (1 + lat_code_log_std.weight - lat_code_mu.weight.pow(2) - lat_code_log_std.weight.exp())).mean()\n",
    "    loss_kl *= param[\"lambda_kl\"]\n",
    "\n",
    "    return loss_sdf, loss_rgb, loss_kl\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Loading parameters...\")\n",
    "\n",
    "    # load parameters\n",
    "    param_all = json.load(open(PARAM_FILE))\n",
    "    param = param_all[\"decoder\"]\n",
    "\n",
    "    resolution = RESOLUTION\n",
    "    num_samples_per_model = resolution * resolution * resolution\n",
    "    threshold_precision = 1.0/resolution\n",
    "\n",
    "    # get models' hashs\n",
    "    list_model_hash = []\n",
    "    for val in glob.glob(SDF_DIR + \"*.h5\"):\n",
    "        list_model_hash.append(os.path.basename(val).split('.')[0])\n",
    "    num_model = len(list_model_hash)\n",
    "\n",
    "    # dataLoader for training dataset\n",
    "    training_dataset = DatasetDecoder(list_model_hash, SDF_DIR, resolution)\n",
    "    training_generator = torch.utils.data.DataLoader(training_dataset, **param[\"dataLoader\"])\n",
    "\n",
    "    # fill a xyz grid to give as input to the decoder \n",
    "    xyz = init_xyz(resolution)\n",
    "\n",
    "    # initialize a random latent code for each models\n",
    "    lat_code_mu, lat_code_log_std = init_lat_vecs(num_model, param[\"latent_size\"])\n",
    "\n",
    "    # create a dictionary going from an hash to a corresponding index\n",
    "    idx = torch.arange(num_model).type(torch.LongTensor).cuda()\n",
    "    dict_model_hash_2_idx = dict()\n",
    "    for model_hash, i in zip(list_model_hash, range(num_model)):\n",
    "        dict_model_hash_2_idx[model_hash] = idx[i]\n",
    "\n",
    "    # initialize decoder\n",
    "    decoder = Decoder(param[\"latent_size\"]).cuda()\n",
    "\n",
    "    # initialize optimizer and scheduler\n",
    "    optimizer, scheduler = init_opt_sched(decoder, lat_code_mu, lat_code_log_std, param[\"optimizer\"])\n",
    "\n",
    "\n",
    "    # logs\n",
    "    logs = dict()\n",
    "    logs[\"total\"] = []\n",
    "    logs[\"sdf\"] = []\n",
    "    logs[\"rgb\"] = []\n",
    "    logs[\"reg\"] = []\n",
    "\n",
    "    print(\"Start training...\")\n",
    "    decoder.train()\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    for epoch in range (param[\"num_epoch\"]):\n",
    "        model_count = 0\n",
    "        for hash, sdf_gt, rgb_gt in training_generator:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # only 1 sample per batch!\n",
    "            # hash = hash[0]\n",
    "            # sdf_gt = sdf_gt[0]\n",
    "            # rgb_gt = rgb_gt[0]\n",
    "\n",
    "            # transfer to gpu\n",
    "            sdf_gt = sdf_gt.cuda()\n",
    "            rgb_gt = rgb_gt.cuda()\n",
    "\n",
    "            ##### compute sdf prediction #####\n",
    "            # code_mu, code_log_std = lat_code_mu(dict_model_hash_2_idx[hash]), lat_code_log_std(dict_model_hash_2_idx[hash])\n",
    "            # latent_code =  torch.empty(num_samples_per_model, param[\"latent_size\"]).normal_().cuda() * code_log_std.exp() * param[\"lambda_variance\"] + code_mu\n",
    "\n",
    "            # pred = decoder(latent_code, xyz)\n",
    "\n",
    "            code_log_std = []\n",
    "            code_mu = []\n",
    "            latent_code_list = []\n",
    "            a = torch.empty(sdf_gt.shape[0], param[\"latent_size\"]).normal_().cuda()\n",
    "\n",
    "            for i in range(len(hash)):\n",
    "                code_mu.append(lat_code_mu(dict_model_hash_2_idx[hash[i]]))\n",
    "                code_log_std.append(lat_code_log_std(dict_model_hash_2_idx[hash[i]]))\n",
    "                latent_code_list.append(a[i] * code_log_std[i].exp() * param[\"lambda_variance\"] + code_mu[i])\n",
    "\n",
    "            latent_code = torch.empty([len(latent_code_list), param[\"latent_size\"]]).cuda()\n",
    "            for i in range(len(latent_code)):\n",
    "                latent_code[i] = latent_code_list[i]\n",
    "\n",
    "            pred = decoder(latent_code.repeat_interleave(1000, dim=0), xyz[:1000].repeat(sdf_gt.shape[0],1))\n",
    "\n",
    "            ##### compute loss and store logs #####\n",
    "            pred_sdf = pred[:,0]\n",
    "            pred_rgb = pred[:,1:]\n",
    "            loss_sdf, loss_rgb, loss_kl = compute_loss(pred_sdf, pred_rgb, sdf_gt.reshape(sdf_gt.shape[0] * 1000), rgb_gt.reshape(sdf_gt.shape[0] * 1000, 3), threshold_precision, param)\n",
    "            \n",
    "            loss_total = loss_sdf + loss_rgb + loss_kl\n",
    "\n",
    "            #log\n",
    "            logs[\"total\"].append(loss_total.detach().cpu())\n",
    "            logs[\"sdf\"].append(loss_sdf.detach().cpu())\n",
    "            logs[\"rgb\"].append(loss_rgb.detach().cpu())\n",
    "            logs[\"reg\"].append(loss_kl.detach().cpu())\n",
    "\n",
    "            #update weights\n",
    "            loss_total.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # estime time left\n",
    "            model_count += 1\n",
    "            time_left = compute_time_left(time_start, model_count, num_model, epoch, param[\"num_epoch\"])\n",
    "\n",
    "            # print\n",
    "            print(\"Epoch {} / {:.2f}% ,loss: sdf: {:.5f}, rgb: {:.5f}, reg: {:.5f}, min/max sdf: {:.2f}/{:.2f}, min/max rgb: {:.2f}/{:.2f}, code std/mu: {:.2f}/{:.2f}, time left: {} min\".format(\\\n",
    "                epoch, model_count / num_model * 100, loss_sdf, loss_rgb, loss_kl, \\\n",
    "                pred_sdf.min() * resolution, pred_sdf.max() * resolution, pred_rgb.min() * 255, pred_rgb.max() * 255, \\\n",
    "                (lat_code_log_std.weight.exp()).mean(), (lat_code_mu.weight).abs().mean(), (int)(time_left/60)))\n",
    "\n",
    "            if (loss_sdf.isnan()):\n",
    "                IPython.embed\n",
    "                \n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Training finish in {(int)((time.time() - time_start) / 60)} min\")\n",
    "\n",
    "\n",
    "    with open(LOGS_PATH, \"wb\") as fp:\n",
    "        pickle.dump(logs, fp)\n",
    "    \n",
    "    \n",
    "    dict_hash_2_code = dict()\n",
    "    for model_hash in list_model_hash:\n",
    "        dict_hash_2_code[model_hash] = lat_code_mu(dict_model_hash_2_idx[hash])\n",
    "\n",
    "    with open(LATENT_CODE_PATH, \"wb\") as fp:\n",
    "        pickle.dump(logs, fp)\n",
    "\n",
    "\n",
    "\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading parameters...\n",
      "Start training...\n",
      "Epoch 0 / 0.41% ,loss: sdf: 0.42551, rgb: 0.00617, reg: 0.00102, min/max sdf: -31.92/102.15, min/max rgb: 14.73/244.05, code std/mu: 1.00/0.80, time left: 3363 min\n",
      "Epoch 0 / 0.81% ,loss: sdf: 0.36415, rgb: 0.00763, reg: 0.00101, min/max sdf: -23.15/78.85, min/max rgb: 4.63/246.78, code std/mu: 1.00/0.80, time left: 2194 min\n",
      "Epoch 0 / 1.22% ,loss: sdf: 0.36525, rgb: 0.00809, reg: 0.00100, min/max sdf: -23.15/66.77, min/max rgb: 3.57/242.24, code std/mu: 1.00/0.79, time left: 1550 min\n",
      "Epoch 0 / 1.63% ,loss: sdf: 0.34216, rgb: 0.00666, reg: 0.00100, min/max sdf: -17.27/68.78, min/max rgb: 14.11/235.62, code std/mu: 1.00/0.79, time left: 1263 min\n",
      "Epoch 0 / 2.03% ,loss: sdf: 0.37683, rgb: 0.00700, reg: 0.00099, min/max sdf: -48.28/67.77, min/max rgb: 15.18/240.30, code std/mu: 1.00/0.79, time left: 1091 min\n",
      "Epoch 0 / 2.44% ,loss: sdf: 0.35690, rgb: 0.00533, reg: 0.00098, min/max sdf: -21.36/82.90, min/max rgb: 22.84/233.93, code std/mu: 1.00/0.78, time left: 955 min\n",
      "Epoch 0 / 2.85% ,loss: sdf: 0.45520, rgb: 0.00523, reg: 0.00098, min/max sdf: -30.22/79.45, min/max rgb: 8.92/247.42, code std/mu: 1.00/0.78, time left: 874 min\n",
      "Epoch 0 / 3.25% ,loss: sdf: 0.39384, rgb: 0.00428, reg: 0.00097, min/max sdf: -31.04/110.11, min/max rgb: 14.01/241.40, code std/mu: 1.00/0.78, time left: 795 min\n",
      "Epoch 0 / 3.66% ,loss: sdf: 0.29587, rgb: 0.00539, reg: 0.00097, min/max sdf: -21.35/101.78, min/max rgb: 9.53/243.38, code std/mu: 1.00/0.77, time left: 740 min\n",
      "Epoch 0 / 4.07% ,loss: sdf: 0.28904, rgb: 0.00617, reg: 0.00096, min/max sdf: -16.98/70.65, min/max rgb: 16.81/242.79, code std/mu: 1.00/0.77, time left: 708 min\n",
      "Epoch 0 / 4.47% ,loss: sdf: 0.31683, rgb: 0.00471, reg: 0.00096, min/max sdf: -11.76/57.36, min/max rgb: 8.21/248.49, code std/mu: 1.00/0.77, time left: 666 min\n",
      "Epoch 0 / 4.88% ,loss: sdf: 0.38670, rgb: 0.00546, reg: 0.00096, min/max sdf: -27.97/73.04, min/max rgb: 11.60/249.10, code std/mu: 1.00/0.77, time left: 635 min\n",
      "Epoch 0 / 5.28% ,loss: sdf: 0.39295, rgb: 0.00730, reg: 0.00095, min/max sdf: -28.92/64.78, min/max rgb: 5.22/240.79, code std/mu: 1.00/0.76, time left: 608 min\n",
      "Epoch 0 / 5.69% ,loss: sdf: 0.38609, rgb: 0.00391, reg: 0.00095, min/max sdf: -19.39/77.45, min/max rgb: 9.85/241.57, code std/mu: 1.00/0.76, time left: 584 min\n",
      "Epoch 0 / 6.10% ,loss: sdf: 0.47570, rgb: 0.00526, reg: 0.00095, min/max sdf: -35.20/88.30, min/max rgb: 7.92/248.70, code std/mu: 1.00/0.76, time left: 563 min\n",
      "Epoch 0 / 6.50% ,loss: sdf: 0.36880, rgb: 0.00781, reg: 0.00094, min/max sdf: -21.43/107.28, min/max rgb: 16.48/228.94, code std/mu: 1.00/0.76, time left: 545 min\n",
      "Epoch 0 / 6.91% ,loss: sdf: 0.30315, rgb: 0.00438, reg: 0.00094, min/max sdf: -21.10/75.11, min/max rgb: 19.14/242.50, code std/mu: 1.00/0.76, time left: 527 min\n",
      "Epoch 0 / 7.32% ,loss: sdf: 0.38487, rgb: 0.00715, reg: 0.00094, min/max sdf: -18.89/69.39, min/max rgb: 15.96/233.33, code std/mu: 1.00/0.76, time left: 515 min\n",
      "Epoch 0 / 7.72% ,loss: sdf: 0.26486, rgb: 0.00653, reg: 0.00094, min/max sdf: -8.45/67.69, min/max rgb: 10.74/234.86, code std/mu: 1.00/0.75, time left: 506 min\n",
      "Epoch 0 / 8.13% ,loss: sdf: 0.33712, rgb: 0.00520, reg: 0.00093, min/max sdf: -22.64/66.19, min/max rgb: 1.18/239.05, code std/mu: 1.00/0.75, time left: 490 min\n",
      "Epoch 0 / 8.54% ,loss: sdf: 0.25791, rgb: 0.00543, reg: 0.00093, min/max sdf: -13.19/86.80, min/max rgb: 7.71/232.70, code std/mu: 1.00/0.75, time left: 479 min\n",
      "Epoch 0 / 8.94% ,loss: sdf: 0.35142, rgb: 0.00288, reg: 0.00093, min/max sdf: -12.62/74.11, min/max rgb: 4.61/230.37, code std/mu: 1.00/0.75, time left: 470 min\n",
      "Epoch 0 / 9.35% ,loss: sdf: 0.17599, rgb: 0.00630, reg: 0.00093, min/max sdf: -1.39/68.19, min/max rgb: 10.75/237.77, code std/mu: 1.00/0.75, time left: 462 min\n",
      "Epoch 0 / 9.76% ,loss: sdf: 0.33012, rgb: 0.00875, reg: 0.00093, min/max sdf: -9.31/72.18, min/max rgb: 9.36/243.60, code std/mu: 1.00/0.75, time left: 455 min\n",
      "Epoch 0 / 10.16% ,loss: sdf: nan, rgb: nan, reg: 0.00093, min/max sdf: 1.92/103.81, min/max rgb: 5.93/241.74, code std/mu: nan/nan, time left: 446 min\n",
      "Epoch 1 / 0.41% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 56 min\n",
      "Epoch 1 / 0.81% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 57 min\n",
      "Epoch 1 / 1.22% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 58 min\n",
      "Epoch 1 / 1.63% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 59 min\n",
      "Epoch 1 / 2.03% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 59 min\n",
      "Epoch 1 / 2.44% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 60 min\n",
      "Epoch 1 / 2.85% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 61 min\n",
      "Epoch 1 / 3.25% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 62 min\n",
      "Epoch 1 / 3.66% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 63 min\n",
      "Epoch 1 / 4.07% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 63 min\n",
      "Epoch 1 / 4.47% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 64 min\n",
      "Epoch 1 / 4.88% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 64 min\n",
      "Epoch 1 / 5.28% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 65 min\n",
      "Epoch 1 / 5.69% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 66 min\n",
      "Epoch 1 / 6.10% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 66 min\n",
      "Epoch 1 / 6.50% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 67 min\n",
      "Epoch 1 / 6.91% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 68 min\n",
      "Epoch 1 / 7.32% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 68 min\n",
      "Epoch 1 / 7.72% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 69 min\n",
      "Epoch 1 / 8.13% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 69 min\n",
      "Epoch 1 / 8.54% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 70 min\n",
      "Epoch 1 / 8.94% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 70 min\n",
      "Epoch 1 / 9.35% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 71 min\n",
      "Epoch 1 / 9.76% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 72 min\n",
      "Epoch 1 / 10.16% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 72 min\n",
      "Epoch 2 / 0.41% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 44 min\n",
      "Epoch 2 / 0.81% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 45 min\n",
      "Epoch 2 / 1.22% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 45 min\n",
      "Epoch 2 / 1.63% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 46 min\n",
      "Epoch 2 / 2.03% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 46 min\n",
      "Epoch 2 / 2.44% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 47 min\n",
      "Epoch 2 / 2.85% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 47 min\n",
      "Epoch 2 / 3.25% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 47 min\n",
      "Epoch 2 / 3.66% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 48 min\n",
      "Epoch 2 / 4.07% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 48 min\n",
      "Epoch 2 / 4.47% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 48 min\n",
      "Epoch 2 / 4.88% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 49 min\n",
      "Epoch 2 / 5.28% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 49 min\n",
      "Epoch 2 / 5.69% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 49 min\n",
      "Epoch 2 / 6.10% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 50 min\n",
      "Epoch 2 / 6.50% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 50 min\n",
      "Epoch 2 / 6.91% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 50 min\n",
      "Epoch 2 / 7.32% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 51 min\n",
      "Epoch 2 / 7.72% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 51 min\n",
      "Epoch 2 / 8.13% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 51 min\n",
      "Epoch 2 / 8.54% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 52 min\n",
      "Epoch 2 / 8.94% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 52 min\n",
      "Epoch 2 / 9.35% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 52 min\n",
      "Epoch 2 / 9.76% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 53 min\n",
      "Epoch 2 / 10.16% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 53 min\n",
      "Epoch 3 / 0.41% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 41 min\n",
      "Epoch 3 / 0.81% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 41 min\n",
      "Epoch 3 / 1.22% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 42 min\n",
      "Epoch 3 / 1.63% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 43 min\n",
      "Epoch 3 / 2.03% ,loss: sdf: nan, rgb: nan, reg: nan, min/max sdf: nan/nan, min/max rgb: nan/nan, code std/mu: nan/nan, time left: 43 min\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27833/3758923750.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mlatent_code\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_code_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m##### compute loss and store logs #####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MasterPDM/codePDM/img2sdf_code/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, latent_code, xyz)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use cumulative moving average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "code_mu"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([nan, nan, nan, nan, nan, nan], device='cuda:0',\n",
       "        grad_fn=<EmbeddingBackward>),\n",
       " tensor([nan, nan, nan, nan, nan, nan], device='cuda:0',\n",
       "        grad_fn=<EmbeddingBackward>),\n",
       " tensor([nan, nan, nan, nan, nan, nan], device='cuda:0',\n",
       "        grad_fn=<EmbeddingBackward>),\n",
       " tensor([nan, nan, nan, nan, nan, nan], device='cuda:0',\n",
       "        grad_fn=<EmbeddingBackward>),\n",
       " tensor([nan, nan, nan, nan, nan, nan], device='cuda:0',\n",
       "        grad_fn=<EmbeddingBackward>),\n",
       " tensor([nan, nan, nan, nan, nan, nan], device='cuda:0',\n",
       "        grad_fn=<EmbeddingBackward>),\n",
       " tensor([nan, nan, nan, nan, nan, nan], device='cuda:0',\n",
       "        grad_fn=<EmbeddingBackward>),\n",
       " tensor([nan, nan, nan, nan, nan, nan], device='cuda:0',\n",
       "        grad_fn=<EmbeddingBackward>),\n",
       " tensor([nan, nan, nan, nan, nan, nan], device='cuda:0',\n",
       "        grad_fn=<EmbeddingBackward>),\n",
       " tensor([nan, nan, nan, nan, nan, nan], device='cuda:0',\n",
       "        grad_fn=<EmbeddingBackward>)]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "sdf_gt.reshape(10000)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.5680, 0.5619, 0.5560,  ..., 0.3888, 0.3854, 0.3823], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "IPython.embed()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python 3.9.2 (default, Feb 28 2021, 17:03:44) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 7.27.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27833/564509750.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/terminal/embed.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m     shell = InteractiveShellEmbed.instance(_init_location_id='%s:%s' % (\n\u001b[1;32m    387\u001b[0m         frame.f_code.co_filename, frame.f_lineno), **kwargs)\n\u001b[0;32m--> 388\u001b[0;31m     shell(header=header, stack_depth=2, compile_flags=compile_flags,\n\u001b[0m\u001b[1;32m    389\u001b[0m         _call_location_id='%s:%s' % (frame.f_code.co_filename, frame.f_lineno))\n\u001b[1;32m    390\u001b[0m     \u001b[0mInteractiveShellEmbed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/terminal/embed.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, header, local_ns, module, dummy, stack_depth, global_ns, compile_flags, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Call the embedding code with a stack depth of 1 so it can skip over\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# our call and get the original caller's namespaces.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         self.mainloop(local_ns, module, stack_depth=stack_depth,\n\u001b[0m\u001b[1;32m    229\u001b[0m                       global_ns=global_ns, compile_flags=compile_flags)\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/terminal/embed.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, local_ns, module, stack_depth, display_banner, global_ns, compile_flags)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# now, purge out the local namespace of IPython's hidden variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/terminal/interactiveshell.py\u001b[0m in \u001b[0;36minteract\u001b[0;34m(self, display_banner)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_for_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfirm_exit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/terminal/interactiveshell.py\u001b[0m in \u001b[0;36mprompt\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mprompt_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_prompt_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mprompt_continuation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuation_prompt_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'incomplete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/utils/py3compat.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;31m# to forward requests to a frontend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuiltin_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0mbuiltin_mod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"builtins\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             )\n\u001b[0;32m-> 1006\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "\n",
    "loss_sdf, loss_rgb, loss_kl = compute_loss(pred_sdf, pred_rgb, sdf_gt.reshape(10000), rgb_gt.reshape(10000,3), threshold_precision, param)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "a = torch.tensor([[1,2,2],[3,4,3]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "a[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 2, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "rgb_gt[:2,100:102]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000],\n",
       "         [0.1373, 0.1373, 0.1373]],\n",
       "\n",
       "        [[0.1098, 0.1098, 0.1098],\n",
       "         [1.0000, 0.4745, 0.0000]]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "rgb_gt[:2,100:102].reshape(4,3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000],\n",
       "        [0.1373, 0.1373, 0.1373],\n",
       "        [0.1098, 0.1098, 0.1098],\n",
       "        [1.0000, 0.4745, 0.0000]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}