{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "LOGS_PATH = \"../../image2sdf/logs/decoder/log.pkl\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logs = pickle.load(open(LOGS_PATH, 'rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "logs.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(logs[\"sdf\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "avrg_sdf = []\n",
    "for i in range(len(logs[\"sdf\"]) - 246):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    avrg_sdf.append(np.mean(logs[\"sdf\"][i : i + 246]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(np.mean(logs[\"sdf\"][-246:]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "\n",
    "from networks import Decoder\n",
    "from dataLoader import DatasetDecoder\n",
    "from marching_cubes_rgb import *\n",
    "\n",
    "import IPython\n",
    "\n",
    "# directory which contain the SDF input and where all the output will be generated\n",
    "MAIN_DIR = \"../../image2sdf/\"\n",
    "# MAIN_DIR = \"/home/loic/MasterPDM/image2sdf/\"\n",
    "\n",
    "DECODER_PATH = \"models_and_codes/decoderSDF.pth\"\n",
    "LATENT_CODE_PATH = \"models_and_codes/latent_code.pkl\"\n",
    "LOGS_PATH = \"../../image2sdf/logs/log.pkl\"\n",
    "PARAM_FILE = \"config/param.json\"\n",
    "\n",
    "SDF_DIR = MAIN_DIR + \"sdf/\"\n",
    "RESOLUTION = 64\n",
    "\n",
    "\n",
    "\n",
    "def init_xyz(resolution):\n",
    "    \"\"\" fill 3d grid representing 3d location to give as input to the decoder \"\"\"\n",
    "    xyz = torch.empty(resolution * resolution * resolution, 3).cuda()\n",
    "\n",
    "    for x in range(resolution):\n",
    "        for y in range(resolution):\n",
    "            for z in range(resolution):\n",
    "                xyz[x * resolution * resolution + y * resolution + z, :] = torch.Tensor([x/(resolution-1)-0.5,y/(resolution-1)-0.5,z/(resolution-1)-0.5])\n",
    "\n",
    "    return xyz\n",
    "\n",
    "def init_lat_vecs(num_scenes, latent_size):\n",
    "    \"\"\"initialize random latent code for every model\"\"\"\n",
    "\n",
    "    lat_code_mu = torch.nn.Embedding(num_scenes, latent_size).cuda()\n",
    "    torch.nn.init.normal_(\n",
    "        lat_code_mu.weight.data,\n",
    "        0.0,\n",
    "        1.0,\n",
    "    )\n",
    "    lat_code_log_std = torch.nn.Embedding(num_scenes, latent_size).cuda()\n",
    "    torch.nn.init.normal_(\n",
    "        lat_code_log_std.weight.data,\n",
    "        0.0,\n",
    "        0.0,\n",
    "    )\n",
    "\n",
    "    return lat_code_mu, lat_code_log_std\n",
    "\n",
    "def init_opt_sched(decoder, lat_vecs_mu, lat_vecs_log_std, param):\n",
    "    \"\"\" initialize optimizer and scheduler\"\"\"\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {\n",
    "                \"params\": decoder.parameters(),\n",
    "                \"lr\": param[\"eta_decoder\"],\n",
    "            },\n",
    "            {\n",
    "                \"params\": lat_vecs_mu.parameters(),\n",
    "                \"lr\": param[\"eta_latent_space_mu\"],\n",
    "            },\n",
    "            {\n",
    "                \"params\": lat_vecs_log_std.parameters(),\n",
    "                \"lr\": param[\"eta_latent_space_std\"],\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=param[\"gammaLR\"])\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "def compute_time_left(time_start, model_count, num_model, epoch, num_epoch):\n",
    "    \"\"\" Compute time left until the end of training \"\"\"\n",
    "    time_passed = time.time() - time_start\n",
    "    num_model_seen = epoch * num_model + model_count\n",
    "    time_per_model = time_passed/num_model_seen\n",
    "    estimate_total_time = time_per_model * num_epoch * num_model\n",
    "    estimate_time_left = estimate_total_time - time_passed\n",
    "\n",
    "    return estimate_time_left\n",
    "\n",
    "def compute_loss(pred_sdf, pred_rgb, sdf_gt, rgb_gt, threshold_precision, param):\n",
    "    \"\"\" compute sdf, rgb and regression loss \"\"\"\n",
    "\n",
    "    loss = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "    # assign weight of 0 for easy samples that are well trained\n",
    "    weight_sdf = ~((pred_sdf > threshold_precision).squeeze() * (sdf_gt > threshold_precision).squeeze()) \\\n",
    "        * ~((pred_sdf < -threshold_precision).squeeze() * (sdf_gt < -threshold_precision).squeeze())\n",
    "\n",
    "    #L2 loss, only for hard samples\n",
    "    loss_sdf = loss(pred_sdf.squeeze(), sdf_gt)\n",
    "    loss_sdf = (loss_sdf * weight_sdf).sum()/weight_sdf.count_nonzero()\n",
    "    loss_sdf *= param[\"lambda_sdf\"]\n",
    "\n",
    "    # loss rgb\n",
    "    loss_rgb = loss(pred_rgb, rgb_gt)\n",
    "    loss_rgb = ((loss_rgb[:,0] * weight_sdf) + (loss_rgb[:,1] * weight_sdf) + (loss_rgb[:,2] * weight_sdf)).sum()/weight_sdf.count_nonzero()\n",
    "    loss_rgb *= param[\"lambda_rgb\"]\n",
    "    \n",
    "    # regularization loss\n",
    "    loss_kl = (-0.5 * (1 + lat_code_log_std.weight - lat_code_mu.weight.pow(2) - lat_code_log_std.weight.exp())).mean()\n",
    "    loss_kl *= param[\"lambda_kl\"]\n",
    "\n",
    "    return loss_sdf, loss_rgb, loss_kl\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Loading parameters...\")\n",
    "\n",
    "    # load parameters\n",
    "    param_all = json.load(open(PARAM_FILE))\n",
    "    param = param_all[\"decoder\"]\n",
    "\n",
    "    resolution = RESOLUTION\n",
    "    threshold_precision = 1.0/resolution\n",
    "    # num_samples_per_model = resolution * resolution * resolution\n",
    "    num_samples_per_model = param[\"num_samples_per_model\"]\n",
    "    batch_size = param[\"dataLoader\"][\"batch_size\"]\n",
    "\n",
    "    # get models' hashs\n",
    "    list_model_hash = []\n",
    "    for val in glob.glob(SDF_DIR + \"*.h5\"):\n",
    "        list_model_hash.append(os.path.basename(val).split('.')[0])\n",
    "    num_model = len(list_model_hash)\n",
    "\n",
    "    # fill a xyz grid to give as input to the decoder \n",
    "    xyz = init_xyz(resolution)\n",
    "\n",
    "    # initialize a random latent code for each models\n",
    "    lat_code_mu, lat_code_log_std = init_lat_vecs(num_model, param[\"latent_size\"])\n",
    "\n",
    "    # create a dictionary going from an hash to a corresponding index\n",
    "    idx = torch.arange(num_model).type(torch.LongTensor).cuda()\n",
    "    dict_model_hash_2_idx = dict()\n",
    "    for model_hash, i in zip(list_model_hash, range(num_model)):\n",
    "        dict_model_hash_2_idx[model_hash] = idx[i]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "code_mu"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sdf_gt.reshape(10000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "IPython.embed()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "loss_sdf, loss_rgb, loss_kl = compute_loss(pred_sdf, pred_rgb, sdf_gt.reshape(10000), rgb_gt.reshape(10000,3), threshold_precision, param)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = torch.tensor([[1,2,2],[3,4,3]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rgb_gt[:2,100:102]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rgb_gt[:2,100:102].reshape(4,3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}