{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from types import resolve_bases\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "\n",
    "from networks import Decoder\n",
    "from dataLoader import DatasetDecoder\n",
    "from marching_cubes_rgb import *\n",
    "\n",
    "import IPython\n",
    "\n",
    "# directory which contain the SDF input and where all the output will be generated\n",
    "MAIN_DIR = \"../../image2sdf/\"\n",
    "# MAIN_DIR = \"/home/loic/MasterPDM/image2sdf/\"\n",
    "\n",
    "DECODER_PATH = \"models_and_codes/decoderSDF.pth\"\n",
    "LATENT_CODE_PATH = \"models_and_codes/latent_code.pkl\"\n",
    "PARAM_FILE = \"config/param.json\"\n",
    "\n",
    "SDF_DIR = MAIN_DIR + \"sdf/\"\n",
    "RESOLUTION = 64\n",
    "\n",
    "\n",
    "\n",
    "def init_xyz(resolution):\n",
    "    \"\"\" fill 3d grid representing 3d location to give as input to the decoder \"\"\"\n",
    "    xyz = torch.empty(resolution * resolution * resolution, 3).cuda()\n",
    "\n",
    "    for x in range(resolution):\n",
    "        for y in range(resolution):\n",
    "            for z in range(resolution):\n",
    "                xyz[x * resolution * resolution + y * resolution + z, :] = torch.Tensor([x/(resolution-1)-0.5,y/(resolution-1)-0.5,z/(resolution-1)-0.5])\n",
    "\n",
    "    return xyz\n",
    "\n",
    "def init_lat_vecs(num_scenes, latent_size):\n",
    "    \"\"\"initialize random latent code for every model\"\"\"\n",
    "\n",
    "    lat_code_mu = torch.nn.Embedding(num_scenes, latent_size).cuda()\n",
    "    torch.nn.init.normal_(\n",
    "        lat_code_mu.weight.data,\n",
    "        0.0,\n",
    "        1.0,\n",
    "    )\n",
    "    lat_code_log_std = torch.nn.Embedding(num_scenes, latent_size).cuda()\n",
    "    torch.nn.init.normal_(\n",
    "        lat_code_log_std.weight.data,\n",
    "        0.0,\n",
    "        0.0,\n",
    "    )\n",
    "\n",
    "    return lat_code_mu, lat_code_log_std\n",
    "\n",
    "def init_opt_sched(decoder, lat_vecs_mu, lat_vecs_log_std, param):\n",
    "    \"\"\" initialize optimizer and scheduler\"\"\"\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {\n",
    "                \"params\": decoder.parameters(),\n",
    "                \"lr\": param[\"eta_decoder\"],\n",
    "            },\n",
    "            {\n",
    "                \"params\": lat_vecs_mu.parameters(),\n",
    "                \"lr\": param[\"eta_latent_space_mu\"],\n",
    "            },\n",
    "            {\n",
    "                \"params\": lat_vecs_log_std.parameters(),\n",
    "                \"lr\": param[\"eta_latent_space_std\"],\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=param[\"gammaLR\"])\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Loading parameters...\")\n",
    "\n",
    "    # load parameters\n",
    "    param_all = json.load(open(PARAM_FILE))\n",
    "    param = param_all[\"decoder\"]\n",
    "\n",
    "    resolution = RESOLUTION\n",
    "    num_samples_per_model = resolution * resolution * resolution\n",
    "    threshold_precision = 1.0/resolution\n",
    "\n",
    "    # get models' hashs\n",
    "    list_model_hash = []\n",
    "    for val in glob.glob(SDF_DIR + \"*.h5\"):\n",
    "        list_model_hash.append(os.path.basename(val).split('.')[0])\n",
    "    num_model = len(list_model_hash)\n",
    "\n",
    "    # dataLoader for training dataset\n",
    "    training_dataset = DatasetDecoder(list_model_hash, SDF_DIR, resolution)\n",
    "    training_generator = torch.utils.data.DataLoader(training_dataset, **param[\"dataLoader\"])\n",
    "\n",
    "    # fill a xyz grid to give as input to the decoder \n",
    "    xyz = init_xyz(resolution)\n",
    "    # initialize a random latent code for each models\n",
    "    lat_code_mu, lat_code_log_std = init_lat_vecs(num_model, param[\"latent_size\"])\n",
    "\n",
    "    idx = torch.arange(num_model).type(torch.LongTensor).cuda()\n",
    "    dict_model_hash_2_idx = dict()\n",
    "    for model_hash, i in zip(list_model_hash, range(num_model)):\n",
    "        dict_model_hash_2_idx[model_hash] = idx[i]\n",
    "\n",
    "    # decoder\n",
    "    decoder = Decoder(param[\"latent_size\"]).cuda()\n",
    "    loss = torch.nn.MSELoss(reduction='none')\n",
    "    # initialize optimizer and scheduler\n",
    "    optimizer, scheduler = init_opt_sched(decoder, lat_code_mu, lat_code_log_std, param[\"optimizer\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Start training...\")\n",
    "\n",
    "    for hash, sdf_gt, rgb_gt in training_generator:\n",
    "        # only 1 sample per batch!\n",
    "        hash = hash[0]\n",
    "        sdf_gt = sdf_gt[0]\n",
    "        rgb_gt = rgb_gt[0]\n",
    "\n",
    "        sdf_gt = sdf_gt.cuda()\n",
    "        rgb_gt = rgb_gt.cuda()\n",
    "\n",
    "        code_mu, code_log_std = lat_code_mu(dict_model_hash_2_idx[hash]), lat_code_log_std(dict_model_hash_2_idx[hash])\n",
    "        latent_code =  torch.empty(num_samples_per_model, param[\"latent_size\"]).normal_().cuda() * code_log_std.exp() * param[\"lambda_variance\"] + code_mu\n",
    "\n",
    "\n",
    "        pred = decoder(latent_code, xyz)\n",
    "\n",
    "\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using skimage's marching cubes implementation.\n",
      "Loading parameters...\n",
      "Start training...\n",
      "37126540\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (262144) must match the size of tensor b (6) at non-singleton dimension 0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8077/901156772.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mcode_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_log_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlat_code_mu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_model_hash_2_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_code_log_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_model_hash_2_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mlatent_code\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples_per_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcode_log_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lambda_variance\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcode_mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (262144) must match the size of tensor b (6) at non-singleton dimension 0"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "a = torch.empty(num_samples_per_model, param[\"latent_size\"]).normal_().cuda()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "code_log_std[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.1000, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "code_log_std.exp()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.1052, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
       "       grad_fn=<ExpBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "a * code_log_std.exp()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.6213e+00, -4.9051e-01,  9.8526e-01, -1.7783e+00,  8.7508e-01,\n",
       "         -5.7617e-01],\n",
       "        [ 6.9454e-01, -7.1401e-01,  3.0229e+00,  1.6118e-01, -2.0640e+00,\n",
       "          1.3472e-03],\n",
       "        [-5.6624e-01, -6.3003e-01, -4.4470e-01,  1.5505e+00, -5.0576e-01,\n",
       "         -1.8991e+00],\n",
       "        ...,\n",
       "        [ 4.1694e-01, -2.2405e+00,  1.5258e-01, -1.0663e+00, -2.0300e+00,\n",
       "         -8.9969e-01],\n",
       "        [ 2.0419e-01,  8.9827e-01,  9.4146e-01, -1.9243e-01, -5.2128e-01,\n",
       "          1.5413e+00],\n",
       "        [-7.8587e-03,  2.0081e-02, -2.0799e-02,  9.9405e-01, -8.5101e-01,\n",
       "         -3.2946e-02]], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.6213e+00, -4.4383e-01,  9.8526e-01, -1.7783e+00,  8.7508e-01,\n",
       "         -5.7617e-01],\n",
       "        [ 6.9454e-01, -6.4606e-01,  3.0229e+00,  1.6118e-01, -2.0640e+00,\n",
       "          1.3472e-03],\n",
       "        [-5.6624e-01, -5.7007e-01, -4.4470e-01,  1.5505e+00, -5.0576e-01,\n",
       "         -1.8991e+00],\n",
       "        ...,\n",
       "        [ 4.1694e-01, -2.0273e+00,  1.5258e-01, -1.0663e+00, -2.0300e+00,\n",
       "         -8.9969e-01],\n",
       "        [ 2.0419e-01,  8.1279e-01,  9.4146e-01, -1.9243e-01, -5.2128e-01,\n",
       "          1.5413e+00],\n",
       "        [-7.8587e-03,  1.8170e-02, -2.0799e-02,  9.9405e-01, -8.5101e-01,\n",
       "         -3.2946e-02]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "code_log_std"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.], device='cuda:0', grad_fn=<EmbeddingBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "b = torch.tensor([[1,2],[3,4],[1,1],[1,1]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "a* b "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [3, 8],\n",
       "        [1, 2],\n",
       "        [1, 2]])"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}